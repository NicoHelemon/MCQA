{
  "config_general": {
    "lighteval_sha": "8113a236038445db7247fc144947cc507c092861",
    "num_fewshot_seeds": 1,
    "override_batch_size": -1,
    "max_samples": null,
    "job_id": 0,
    "start_time": 1051542.756446217,
    "end_time": 1052563.854551089,
    "total_evaluation_time_secondes": "1021.0981048720423",
    "model_name": "arnaultsta/MNLP_M2_mcqa_model",
    "model_sha": "22b14a22bd5e164404e954b5ba1061b5164b7fa4",
    "model_dtype": "torch.float16",
    "model_size": "1.11 GB",
    "generation_parameters": {
      "early_stopping": null,
      "repetition_penalty": null,
      "frequency_penalty": null,
      "length_penalty": null,
      "presence_penalty": null,
      "max_new_tokens": null,
      "min_new_tokens": null,
      "seed": null,
      "stop_tokens": null,
      "temperature": 0.0,
      "top_k": null,
      "min_p": null,
      "top_p": null,
      "truncate_prompt": null,
      "response_format": null
    }
  },
  "results": {
    "original|mmlu:abstract_algebra|0": {
      "acc": 0.36,
      "acc_stderr": 0.04824181513244218
    },
    "original|mmlu:anatomy|0": {
      "acc": 0.5259259259259259,
      "acc_stderr": 0.04313531696750574
    },
    "original|mmlu:astronomy|0": {
      "acc": 0.625,
      "acc_stderr": 0.039397364351956274
    },
    "original|mmlu:business_ethics|0": {
      "acc": 0.56,
      "acc_stderr": 0.04988876515698589
    },
    "original|mmlu:clinical_knowledge|0": {
      "acc": 0.5886792452830188,
      "acc_stderr": 0.030285009259009784
    },
    "original|mmlu:college_biology|0": {
      "acc": 0.6319444444444444,
      "acc_stderr": 0.04032999053960718
    },
    "original|mmlu:college_chemistry|0": {
      "acc": 0.45,
      "acc_stderr": 0.05
    },
    "original|mmlu:college_computer_science|0": {
      "acc": 0.44,
      "acc_stderr": 0.04988876515698589
    },
    "original|mmlu:college_mathematics|0": {
      "acc": 0.37,
      "acc_stderr": 0.04852365870939099
    },
    "original|mmlu:college_medicine|0": {
      "acc": 0.5202312138728323,
      "acc_stderr": 0.03809342081273956
    },
    "original|mmlu:college_physics|0": {
      "acc": 0.38235294117647056,
      "acc_stderr": 0.04835503696107224
    },
    "original|mmlu:computer_security|0": {
      "acc": 0.73,
      "acc_stderr": 0.044619604333847394
    },
    "original|mmlu:conceptual_physics|0": {
      "acc": 0.5574468085106383,
      "acc_stderr": 0.032469569197899575
    },
    "original|mmlu:econometrics|0": {
      "acc": 0.41228070175438597,
      "acc_stderr": 0.04630653203366596
    },
    "original|mmlu:electrical_engineering|0": {
      "acc": 0.6827586206896552,
      "acc_stderr": 0.03878352372138622
    },
    "original|mmlu:elementary_mathematics|0": {
      "acc": 0.4523809523809524,
      "acc_stderr": 0.025634258115554958
    },
    "original|mmlu:formal_logic|0": {
      "acc": 0.38095238095238093,
      "acc_stderr": 0.04343525428949098
    },
    "original|mmlu:global_facts|0": {
      "acc": 0.32,
      "acc_stderr": 0.04688261722621504
    },
    "original|mmlu:high_school_biology|0": {
      "acc": 0.6903225806451613,
      "acc_stderr": 0.02630277498351741
    },
    "original|mmlu:high_school_chemistry|0": {
      "acc": 0.5665024630541872,
      "acc_stderr": 0.03486731727419872
    },
    "original|mmlu:high_school_computer_science|0": {
      "acc": 0.58,
      "acc_stderr": 0.049604496374885836
    },
    "original|mmlu:high_school_european_history|0": {
      "acc": 0.703030303030303,
      "acc_stderr": 0.035679697722680495
    },
    "original|mmlu:high_school_geography|0": {
      "acc": 0.696969696969697,
      "acc_stderr": 0.032742879140268674
    },
    "original|mmlu:high_school_government_and_politics|0": {
      "acc": 0.6476683937823834,
      "acc_stderr": 0.03447478286414357
    },
    "original|mmlu:high_school_macroeconomics|0": {
      "acc": 0.5769230769230769,
      "acc_stderr": 0.02504919787604234
    },
    "original|mmlu:high_school_mathematics|0": {
      "acc": 0.4111111111111111,
      "acc_stderr": 0.029999923508706686
    },
    "original|mmlu:high_school_microeconomics|0": {
      "acc": 0.6680672268907563,
      "acc_stderr": 0.03058869701378364
    },
    "original|mmlu:high_school_physics|0": {
      "acc": 0.40397350993377484,
      "acc_stderr": 0.040064856853653415
    },
    "original|mmlu:high_school_psychology|0": {
      "acc": 0.7467889908256881,
      "acc_stderr": 0.01864407304137504
    },
    "original|mmlu:high_school_statistics|0": {
      "acc": 0.5138888888888888,
      "acc_stderr": 0.03408655867977749
    },
    "original|mmlu:high_school_us_history|0": {
      "acc": 0.6372549019607843,
      "acc_stderr": 0.03374499356319355
    },
    "original|mmlu:high_school_world_history|0": {
      "acc": 0.7046413502109705,
      "acc_stderr": 0.029696338713422886
    },
    "original|mmlu:human_aging|0": {
      "acc": 0.515695067264574,
      "acc_stderr": 0.0335412657542081
    },
    "original|mmlu:human_sexuality|0": {
      "acc": 0.6259541984732825,
      "acc_stderr": 0.042438692422305246
    },
    "original|mmlu:international_law|0": {
      "acc": 0.7024793388429752,
      "acc_stderr": 0.04173349148083498
    },
    "original|mmlu:jurisprudence|0": {
      "acc": 0.6111111111111112,
      "acc_stderr": 0.0471282125742677
    },
    "original|mmlu:logical_fallacies|0": {
      "acc": 0.6012269938650306,
      "acc_stderr": 0.038470214204560246
    },
    "original|mmlu:machine_learning|0": {
      "acc": 0.5357142857142857,
      "acc_stderr": 0.04733667890053756
    },
    "original|mmlu:management|0": {
      "acc": 0.7572815533980582,
      "acc_stderr": 0.04245022486384495
    },
    "original|mmlu:marketing|0": {
      "acc": 0.7863247863247863,
      "acc_stderr": 0.026853450377009164
    },
    "original|mmlu:medical_genetics|0": {
      "acc": 0.63,
      "acc_stderr": 0.04852365870939099
    },
    "original|mmlu:miscellaneous|0": {
      "acc": 0.6181353767560664,
      "acc_stderr": 0.017373732736677576
    },
    "original|mmlu:moral_disputes|0": {
      "acc": 0.5809248554913294,
      "acc_stderr": 0.026564178111422625
    },
    "original|mmlu:moral_scenarios|0": {
      "acc": 0.23798882681564246,
      "acc_stderr": 0.014242630070574915
    },
    "original|mmlu:nutrition|0": {
      "acc": 0.5849673202614379,
      "acc_stderr": 0.028213504177824096
    },
    "original|mmlu:philosophy|0": {
      "acc": 0.5434083601286174,
      "acc_stderr": 0.0282908690541976
    },
    "original|mmlu:prehistory|0": {
      "acc": 0.5493827160493827,
      "acc_stderr": 0.0276847214156562
    },
    "original|mmlu:professional_accounting|0": {
      "acc": 0.41843971631205673,
      "acc_stderr": 0.029427994039419998
    },
    "original|mmlu:professional_law|0": {
      "acc": 0.40221642764015647,
      "acc_stderr": 0.012523646856180178
    },
    "original|mmlu:professional_medicine|0": {
      "acc": 0.5220588235294118,
      "acc_stderr": 0.030343264224213514
    },
    "original|mmlu:professional_psychology|0": {
      "acc": 0.5130718954248366,
      "acc_stderr": 0.020220920829626912
    },
    "original|mmlu:public_relations|0": {
      "acc": 0.6,
      "acc_stderr": 0.0469237132203465
    },
    "original|mmlu:security_studies|0": {
      "acc": 0.5795918367346938,
      "acc_stderr": 0.03160106993449601
    },
    "original|mmlu:sociology|0": {
      "acc": 0.7611940298507462,
      "acc_stderr": 0.03014777593540922
    },
    "original|mmlu:us_foreign_policy|0": {
      "acc": 0.63,
      "acc_stderr": 0.04852365870939099
    },
    "original|mmlu:virology|0": {
      "acc": 0.4578313253012048,
      "acc_stderr": 0.0387862677100236
    },
    "original|mmlu:world_religions|0": {
      "acc": 0.5497076023391813,
      "acc_stderr": 0.03815827365913237
    },
    "original|mmlu:_average|0": {
      "acc": 0.5588035469622167,
      "acc_stderr": 0.036093319290297486
    },
    "all": {
      "acc": 0.5588035469622167,
      "acc_stderr": 0.036093319290297486
    }
  },
  "versions": {
    "original|mmlu:abstract_algebra|0": 0,
    "original|mmlu:anatomy|0": 0,
    "original|mmlu:astronomy|0": 0,
    "original|mmlu:business_ethics|0": 0,
    "original|mmlu:clinical_knowledge|0": 0,
    "original|mmlu:college_biology|0": 0,
    "original|mmlu:college_chemistry|0": 0,
    "original|mmlu:college_computer_science|0": 0,
    "original|mmlu:college_mathematics|0": 0,
    "original|mmlu:college_medicine|0": 0,
    "original|mmlu:college_physics|0": 0,
    "original|mmlu:computer_security|0": 0,
    "original|mmlu:conceptual_physics|0": 0,
    "original|mmlu:econometrics|0": 0,
    "original|mmlu:electrical_engineering|0": 0,
    "original|mmlu:elementary_mathematics|0": 0,
    "original|mmlu:formal_logic|0": 0,
    "original|mmlu:global_facts|0": 0,
    "original|mmlu:high_school_biology|0": 0,
    "original|mmlu:high_school_chemistry|0": 0,
    "original|mmlu:high_school_computer_science|0": 0,
    "original|mmlu:high_school_european_history|0": 0,
    "original|mmlu:high_school_geography|0": 0,
    "original|mmlu:high_school_government_and_politics|0": 0,
    "original|mmlu:high_school_macroeconomics|0": 0,
    "original|mmlu:high_school_mathematics|0": 0,
    "original|mmlu:high_school_microeconomics|0": 0,
    "original|mmlu:high_school_physics|0": 0,
    "original|mmlu:high_school_psychology|0": 0,
    "original|mmlu:high_school_statistics|0": 0,
    "original|mmlu:high_school_us_history|0": 0,
    "original|mmlu:high_school_world_history|0": 0,
    "original|mmlu:human_aging|0": 0,
    "original|mmlu:human_sexuality|0": 0,
    "original|mmlu:international_law|0": 0,
    "original|mmlu:jurisprudence|0": 0,
    "original|mmlu:logical_fallacies|0": 0,
    "original|mmlu:machine_learning|0": 0,
    "original|mmlu:management|0": 0,
    "original|mmlu:marketing|0": 0,
    "original|mmlu:medical_genetics|0": 0,
    "original|mmlu:miscellaneous|0": 0,
    "original|mmlu:moral_disputes|0": 0,
    "original|mmlu:moral_scenarios|0": 0,
    "original|mmlu:nutrition|0": 0,
    "original|mmlu:philosophy|0": 0,
    "original|mmlu:prehistory|0": 0,
    "original|mmlu:professional_accounting|0": 0,
    "original|mmlu:professional_law|0": 0,
    "original|mmlu:professional_medicine|0": 0,
    "original|mmlu:professional_psychology|0": 0,
    "original|mmlu:public_relations|0": 0,
    "original|mmlu:security_studies|0": 0,
    "original|mmlu:sociology|0": 0,
    "original|mmlu:us_foreign_policy|0": 0,
    "original|mmlu:virology|0": 0,
    "original|mmlu:world_religions|0": 0
  },
  "config_tasks": {
    "original|mmlu:abstract_algebra": {
      "name": "mmlu:abstract_algebra",
      "prompt_function": "mmlu_abstract_algebra",
      "hf_repo": "cais/mmlu",
      "hf_subset": "abstract_algebra",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:anatomy": {
      "name": "mmlu:anatomy",
      "prompt_function": "mmlu_anatomy",
      "hf_repo": "cais/mmlu",
      "hf_subset": "anatomy",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 135,
      "effective_num_docs": 135,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:astronomy": {
      "name": "mmlu:astronomy",
      "prompt_function": "mmlu_astronomy",
      "hf_repo": "cais/mmlu",
      "hf_subset": "astronomy",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 152,
      "effective_num_docs": 152,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:business_ethics": {
      "name": "mmlu:business_ethics",
      "prompt_function": "mmlu_business_ethics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "business_ethics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:clinical_knowledge": {
      "name": "mmlu:clinical_knowledge",
      "prompt_function": "mmlu_clinical_knowledge",
      "hf_repo": "cais/mmlu",
      "hf_subset": "clinical_knowledge",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 265,
      "effective_num_docs": 265,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_biology": {
      "name": "mmlu:college_biology",
      "prompt_function": "mmlu_college_biology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_biology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 144,
      "effective_num_docs": 144,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_chemistry": {
      "name": "mmlu:college_chemistry",
      "prompt_function": "mmlu_college_chemistry",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_chemistry",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_computer_science": {
      "name": "mmlu:college_computer_science",
      "prompt_function": "mmlu_college_computer_science",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_computer_science",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_mathematics": {
      "name": "mmlu:college_mathematics",
      "prompt_function": "mmlu_college_mathematics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_mathematics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_medicine": {
      "name": "mmlu:college_medicine",
      "prompt_function": "mmlu_college_medicine",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_medicine",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 173,
      "effective_num_docs": 173,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:college_physics": {
      "name": "mmlu:college_physics",
      "prompt_function": "mmlu_college_physics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "college_physics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 102,
      "effective_num_docs": 102,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:computer_security": {
      "name": "mmlu:computer_security",
      "prompt_function": "mmlu_computer_security",
      "hf_repo": "cais/mmlu",
      "hf_subset": "computer_security",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:conceptual_physics": {
      "name": "mmlu:conceptual_physics",
      "prompt_function": "mmlu_conceptual_physics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "conceptual_physics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 235,
      "effective_num_docs": 235,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:econometrics": {
      "name": "mmlu:econometrics",
      "prompt_function": "mmlu_econometrics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "econometrics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 114,
      "effective_num_docs": 114,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:electrical_engineering": {
      "name": "mmlu:electrical_engineering",
      "prompt_function": "mmlu_electrical_engineering",
      "hf_repo": "cais/mmlu",
      "hf_subset": "electrical_engineering",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 145,
      "effective_num_docs": 145,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:elementary_mathematics": {
      "name": "mmlu:elementary_mathematics",
      "prompt_function": "mmlu_elementary_mathematics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "elementary_mathematics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 378,
      "effective_num_docs": 378,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:formal_logic": {
      "name": "mmlu:formal_logic",
      "prompt_function": "mmlu_formal_logic",
      "hf_repo": "cais/mmlu",
      "hf_subset": "formal_logic",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 126,
      "effective_num_docs": 126,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:global_facts": {
      "name": "mmlu:global_facts",
      "prompt_function": "mmlu_global_facts",
      "hf_repo": "cais/mmlu",
      "hf_subset": "global_facts",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_biology": {
      "name": "mmlu:high_school_biology",
      "prompt_function": "mmlu_high_school_biology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_biology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 310,
      "effective_num_docs": 310,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_chemistry": {
      "name": "mmlu:high_school_chemistry",
      "prompt_function": "mmlu_high_school_chemistry",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_chemistry",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 203,
      "effective_num_docs": 203,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_computer_science": {
      "name": "mmlu:high_school_computer_science",
      "prompt_function": "mmlu_high_school_computer_science",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_computer_science",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_european_history": {
      "name": "mmlu:high_school_european_history",
      "prompt_function": "mmlu_high_school_european_history",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_european_history",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 165,
      "effective_num_docs": 165,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_geography": {
      "name": "mmlu:high_school_geography",
      "prompt_function": "mmlu_high_school_geography",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_geography",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 198,
      "effective_num_docs": 198,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_government_and_politics": {
      "name": "mmlu:high_school_government_and_politics",
      "prompt_function": "mmlu_high_school_government_and_politics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_government_and_politics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 193,
      "effective_num_docs": 193,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_macroeconomics": {
      "name": "mmlu:high_school_macroeconomics",
      "prompt_function": "mmlu_high_school_macroeconomics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_macroeconomics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 390,
      "effective_num_docs": 390,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_mathematics": {
      "name": "mmlu:high_school_mathematics",
      "prompt_function": "mmlu_high_school_mathematics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_mathematics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 270,
      "effective_num_docs": 270,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_microeconomics": {
      "name": "mmlu:high_school_microeconomics",
      "prompt_function": "mmlu_high_school_microeconomics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_microeconomics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 238,
      "effective_num_docs": 238,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_physics": {
      "name": "mmlu:high_school_physics",
      "prompt_function": "mmlu_high_school_physics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_physics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 151,
      "effective_num_docs": 151,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_psychology": {
      "name": "mmlu:high_school_psychology",
      "prompt_function": "mmlu_high_school_psychology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_psychology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 545,
      "effective_num_docs": 545,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_statistics": {
      "name": "mmlu:high_school_statistics",
      "prompt_function": "mmlu_high_school_statistics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_statistics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 216,
      "effective_num_docs": 216,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_us_history": {
      "name": "mmlu:high_school_us_history",
      "prompt_function": "mmlu_high_school_us_history",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_us_history",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 204,
      "effective_num_docs": 204,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:high_school_world_history": {
      "name": "mmlu:high_school_world_history",
      "prompt_function": "mmlu_high_school_world_history",
      "hf_repo": "cais/mmlu",
      "hf_subset": "high_school_world_history",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 237,
      "effective_num_docs": 237,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:human_aging": {
      "name": "mmlu:human_aging",
      "prompt_function": "mmlu_human_aging",
      "hf_repo": "cais/mmlu",
      "hf_subset": "human_aging",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 223,
      "effective_num_docs": 223,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:human_sexuality": {
      "name": "mmlu:human_sexuality",
      "prompt_function": "mmlu_human_sexuality",
      "hf_repo": "cais/mmlu",
      "hf_subset": "human_sexuality",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 131,
      "effective_num_docs": 131,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:international_law": {
      "name": "mmlu:international_law",
      "prompt_function": "mmlu_international_law",
      "hf_repo": "cais/mmlu",
      "hf_subset": "international_law",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 121,
      "effective_num_docs": 121,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:jurisprudence": {
      "name": "mmlu:jurisprudence",
      "prompt_function": "mmlu_jurisprudence",
      "hf_repo": "cais/mmlu",
      "hf_subset": "jurisprudence",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 108,
      "effective_num_docs": 108,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:logical_fallacies": {
      "name": "mmlu:logical_fallacies",
      "prompt_function": "mmlu_logical_fallacies",
      "hf_repo": "cais/mmlu",
      "hf_subset": "logical_fallacies",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 163,
      "effective_num_docs": 163,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:machine_learning": {
      "name": "mmlu:machine_learning",
      "prompt_function": "mmlu_machine_learning",
      "hf_repo": "cais/mmlu",
      "hf_subset": "machine_learning",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 112,
      "effective_num_docs": 112,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:management": {
      "name": "mmlu:management",
      "prompt_function": "mmlu_management",
      "hf_repo": "cais/mmlu",
      "hf_subset": "management",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 103,
      "effective_num_docs": 103,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:marketing": {
      "name": "mmlu:marketing",
      "prompt_function": "mmlu_marketing",
      "hf_repo": "cais/mmlu",
      "hf_subset": "marketing",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 234,
      "effective_num_docs": 234,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:medical_genetics": {
      "name": "mmlu:medical_genetics",
      "prompt_function": "mmlu_medical_genetics",
      "hf_repo": "cais/mmlu",
      "hf_subset": "medical_genetics",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:miscellaneous": {
      "name": "mmlu:miscellaneous",
      "prompt_function": "mmlu_miscellaneous",
      "hf_repo": "cais/mmlu",
      "hf_subset": "miscellaneous",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 783,
      "effective_num_docs": 783,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:moral_disputes": {
      "name": "mmlu:moral_disputes",
      "prompt_function": "mmlu_moral_disputes",
      "hf_repo": "cais/mmlu",
      "hf_subset": "moral_disputes",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 346,
      "effective_num_docs": 346,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:moral_scenarios": {
      "name": "mmlu:moral_scenarios",
      "prompt_function": "mmlu_moral_scenarios",
      "hf_repo": "cais/mmlu",
      "hf_subset": "moral_scenarios",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 895,
      "effective_num_docs": 895,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:nutrition": {
      "name": "mmlu:nutrition",
      "prompt_function": "mmlu_nutrition",
      "hf_repo": "cais/mmlu",
      "hf_subset": "nutrition",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 306,
      "effective_num_docs": 306,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:philosophy": {
      "name": "mmlu:philosophy",
      "prompt_function": "mmlu_philosophy",
      "hf_repo": "cais/mmlu",
      "hf_subset": "philosophy",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 311,
      "effective_num_docs": 311,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:prehistory": {
      "name": "mmlu:prehistory",
      "prompt_function": "mmlu_prehistory",
      "hf_repo": "cais/mmlu",
      "hf_subset": "prehistory",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 324,
      "effective_num_docs": 324,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:professional_accounting": {
      "name": "mmlu:professional_accounting",
      "prompt_function": "mmlu_professional_accounting",
      "hf_repo": "cais/mmlu",
      "hf_subset": "professional_accounting",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 282,
      "effective_num_docs": 282,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:professional_law": {
      "name": "mmlu:professional_law",
      "prompt_function": "mmlu_professional_law",
      "hf_repo": "cais/mmlu",
      "hf_subset": "professional_law",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 1534,
      "effective_num_docs": 1534,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:professional_medicine": {
      "name": "mmlu:professional_medicine",
      "prompt_function": "mmlu_professional_medicine",
      "hf_repo": "cais/mmlu",
      "hf_subset": "professional_medicine",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 272,
      "effective_num_docs": 272,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:professional_psychology": {
      "name": "mmlu:professional_psychology",
      "prompt_function": "mmlu_professional_psychology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "professional_psychology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 612,
      "effective_num_docs": 612,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:public_relations": {
      "name": "mmlu:public_relations",
      "prompt_function": "mmlu_public_relations",
      "hf_repo": "cais/mmlu",
      "hf_subset": "public_relations",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 110,
      "effective_num_docs": 110,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:security_studies": {
      "name": "mmlu:security_studies",
      "prompt_function": "mmlu_security_studies",
      "hf_repo": "cais/mmlu",
      "hf_subset": "security_studies",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 245,
      "effective_num_docs": 245,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:sociology": {
      "name": "mmlu:sociology",
      "prompt_function": "mmlu_sociology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "sociology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 201,
      "effective_num_docs": 201,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:us_foreign_policy": {
      "name": "mmlu:us_foreign_policy",
      "prompt_function": "mmlu_us_foreign_policy",
      "hf_repo": "cais/mmlu",
      "hf_subset": "us_foreign_policy",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 100,
      "effective_num_docs": 100,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:virology": {
      "name": "mmlu:virology",
      "prompt_function": "mmlu_virology",
      "hf_repo": "cais/mmlu",
      "hf_subset": "virology",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 166,
      "effective_num_docs": 166,
      "must_remove_duplicate_docs": false,
      "version": 0
    },
    "original|mmlu:world_religions": {
      "name": "mmlu:world_religions",
      "prompt_function": "mmlu_world_religions",
      "hf_repo": "cais/mmlu",
      "hf_subset": "world_religions",
      "metric": [
        {
          "metric_name": "acc",
          "higher_is_better": true,
          "category": "10",
          "use_case": "1",
          "sample_level_fn": "compute",
          "corpus_level_fn": "mean"
        }
      ],
      "hf_revision": null,
      "hf_filter": null,
      "hf_avail_splits": [
        "auxiliary_train",
        "test",
        "validation",
        "dev"
      ],
      "trust_dataset": true,
      "limited_num_samples": -1,
      "evaluation_splits": [
        "test"
      ],
      "few_shots_split": "dev",
      "few_shots_select": "sequential",
      "generation_size": 1,
      "generation_grammar": null,
      "stop_sequence": [
        "\n"
      ],
      "num_samples": null,
      "suite": [
        "original",
        "mmlu"
      ],
      "original_num_docs": 171,
      "effective_num_docs": 171,
      "must_remove_duplicate_docs": false,
      "version": 0
    }
  },
  "summary_tasks": {
    "original|mmlu:abstract_algebra|0": {
      "hashes": {
        "hash_examples": "ed56593f2e997ce0",
        "hash_full_prompts": "ed56593f2e997ce0",
        "hash_input_tokens": "d5c156464e916243",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:anatomy|0": {
      "hashes": {
        "hash_examples": "2ace6ded4afc2a5e",
        "hash_full_prompts": "2ace6ded4afc2a5e",
        "hash_input_tokens": "94e03340b938ea29",
        "hash_cont_tokens": "b5670f94fb27b832"
      },
      "truncated": 0,
      "non_truncated": 135,
      "padded": 135,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:astronomy|0": {
      "hashes": {
        "hash_examples": "21203110d0d51583",
        "hash_full_prompts": "21203110d0d51583",
        "hash_input_tokens": "3521ec5fecfddf88",
        "hash_cont_tokens": "6871c2ef565d5500"
      },
      "truncated": 0,
      "non_truncated": 152,
      "padded": 152,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:business_ethics|0": {
      "hashes": {
        "hash_examples": "357288ce2e52447f",
        "hash_full_prompts": "357288ce2e52447f",
        "hash_input_tokens": "76352c9cff8d9b83",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:clinical_knowledge|0": {
      "hashes": {
        "hash_examples": "df848d2f45d1bd48",
        "hash_full_prompts": "df848d2f45d1bd48",
        "hash_input_tokens": "44b38e6da86cd736",
        "hash_cont_tokens": "c9ea23000a6e10a2"
      },
      "truncated": 0,
      "non_truncated": 265,
      "padded": 265,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_biology|0": {
      "hashes": {
        "hash_examples": "bafb726e3bcde3a2",
        "hash_full_prompts": "bafb726e3bcde3a2",
        "hash_input_tokens": "7309c628076402f6",
        "hash_cont_tokens": "b89ba4afafdaf5c5"
      },
      "truncated": 0,
      "non_truncated": 144,
      "padded": 144,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_chemistry|0": {
      "hashes": {
        "hash_examples": "fc285baa5438fc39",
        "hash_full_prompts": "fc285baa5438fc39",
        "hash_input_tokens": "a0b377adced40824",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_computer_science|0": {
      "hashes": {
        "hash_examples": "e9c56c6a2e10361e",
        "hash_full_prompts": "e9c56c6a2e10361e",
        "hash_input_tokens": "e5c7cc490792b3b3",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_mathematics|0": {
      "hashes": {
        "hash_examples": "1d2074d857a90149",
        "hash_full_prompts": "1d2074d857a90149",
        "hash_input_tokens": "decb939cc266ff63",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_medicine|0": {
      "hashes": {
        "hash_examples": "16c3ad1d2d619381",
        "hash_full_prompts": "16c3ad1d2d619381",
        "hash_input_tokens": "21b2543a36b5a31c",
        "hash_cont_tokens": "78435d08bb1eb96b"
      },
      "truncated": 0,
      "non_truncated": 173,
      "padded": 172,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:college_physics|0": {
      "hashes": {
        "hash_examples": "abad045185cbe4c2",
        "hash_full_prompts": "abad045185cbe4c2",
        "hash_input_tokens": "12a3c4a24aa748bc",
        "hash_cont_tokens": "87012dd8330100c6"
      },
      "truncated": 0,
      "non_truncated": 102,
      "padded": 102,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:computer_security|0": {
      "hashes": {
        "hash_examples": "fb8628c671c48396",
        "hash_full_prompts": "fb8628c671c48396",
        "hash_input_tokens": "c2d25db9c0130abf",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:conceptual_physics|0": {
      "hashes": {
        "hash_examples": "2ef684d675c33690",
        "hash_full_prompts": "2ef684d675c33690",
        "hash_input_tokens": "55e6699d541f424a",
        "hash_cont_tokens": "164a045bc0f6da2e"
      },
      "truncated": 0,
      "non_truncated": 235,
      "padded": 235,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:econometrics|0": {
      "hashes": {
        "hash_examples": "67832fed7ca76fae",
        "hash_full_prompts": "67832fed7ca76fae",
        "hash_input_tokens": "e0809eb7b9233536",
        "hash_cont_tokens": "cad1550547a717cf"
      },
      "truncated": 0,
      "non_truncated": 114,
      "padded": 114,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:electrical_engineering|0": {
      "hashes": {
        "hash_examples": "0e47d9122b762b0b",
        "hash_full_prompts": "0e47d9122b762b0b",
        "hash_input_tokens": "d75f772a2180c180",
        "hash_cont_tokens": "066dd137a3f8189a"
      },
      "truncated": 0,
      "non_truncated": 145,
      "padded": 145,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:elementary_mathematics|0": {
      "hashes": {
        "hash_examples": "f3a77048e982d2e0",
        "hash_full_prompts": "f3a77048e982d2e0",
        "hash_input_tokens": "c05cf29b044c43f7",
        "hash_cont_tokens": "5db7656e49468d9b"
      },
      "truncated": 0,
      "non_truncated": 378,
      "padded": 378,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:formal_logic|0": {
      "hashes": {
        "hash_examples": "672c326a37626fc0",
        "hash_full_prompts": "672c326a37626fc0",
        "hash_input_tokens": "62532f3ca8dfac2f",
        "hash_cont_tokens": "9d729eed962ab31c"
      },
      "truncated": 0,
      "non_truncated": 126,
      "padded": 126,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:global_facts|0": {
      "hashes": {
        "hash_examples": "0d756eb39ddcc05f",
        "hash_full_prompts": "0d756eb39ddcc05f",
        "hash_input_tokens": "ca1f2a84116ec7a1",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_biology|0": {
      "hashes": {
        "hash_examples": "d124a13bb2afb6e8",
        "hash_full_prompts": "d124a13bb2afb6e8",
        "hash_input_tokens": "11d48a07f41e3c21",
        "hash_cont_tokens": "029060ae8b4fe03e"
      },
      "truncated": 0,
      "non_truncated": 310,
      "padded": 310,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_chemistry|0": {
      "hashes": {
        "hash_examples": "36fb8856c16dcc39",
        "hash_full_prompts": "36fb8856c16dcc39",
        "hash_input_tokens": "82a2ffb5828de05f",
        "hash_cont_tokens": "08c7da3129780603"
      },
      "truncated": 0,
      "non_truncated": 203,
      "padded": 203,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_computer_science|0": {
      "hashes": {
        "hash_examples": "976a531fabb07328",
        "hash_full_prompts": "976a531fabb07328",
        "hash_input_tokens": "88e8b1574622b757",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 100,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_european_history|0": {
      "hashes": {
        "hash_examples": "e4aba8b1a491b906",
        "hash_full_prompts": "e4aba8b1a491b906",
        "hash_input_tokens": "a4b1352320be7cd9",
        "hash_cont_tokens": "471d750a9fdecd7e"
      },
      "truncated": 0,
      "non_truncated": 165,
      "padded": 165,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_geography|0": {
      "hashes": {
        "hash_examples": "c15417c8523e4faf",
        "hash_full_prompts": "c15417c8523e4faf",
        "hash_input_tokens": "23ac2e7fca16d067",
        "hash_cont_tokens": "d20214178643c9db"
      },
      "truncated": 0,
      "non_truncated": 198,
      "padded": 198,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_government_and_politics|0": {
      "hashes": {
        "hash_examples": "64b6da09817b9c26",
        "hash_full_prompts": "64b6da09817b9c26",
        "hash_input_tokens": "d1d72a678a06c382",
        "hash_cont_tokens": "1dde11d09a7bbac5"
      },
      "truncated": 0,
      "non_truncated": 193,
      "padded": 193,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_macroeconomics|0": {
      "hashes": {
        "hash_examples": "137ad69a53b0a1c9",
        "hash_full_prompts": "137ad69a53b0a1c9",
        "hash_input_tokens": "81b176e48af7ddeb",
        "hash_cont_tokens": "77eecd25e5350dcc"
      },
      "truncated": 0,
      "non_truncated": 390,
      "padded": 387,
      "non_padded": 3,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_mathematics|0": {
      "hashes": {
        "hash_examples": "3281f78b31d6d7fb",
        "hash_full_prompts": "3281f78b31d6d7fb",
        "hash_input_tokens": "0a1b2f1300617c7b",
        "hash_cont_tokens": "73227334f8711d4f"
      },
      "truncated": 0,
      "non_truncated": 270,
      "padded": 268,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_microeconomics|0": {
      "hashes": {
        "hash_examples": "b5b74385f9871eb8",
        "hash_full_prompts": "b5b74385f9871eb8",
        "hash_input_tokens": "d077bb80d97ad1a6",
        "hash_cont_tokens": "29975b6de4f04753"
      },
      "truncated": 0,
      "non_truncated": 238,
      "padded": 238,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_physics|0": {
      "hashes": {
        "hash_examples": "691f7ff06d821e41",
        "hash_full_prompts": "691f7ff06d821e41",
        "hash_input_tokens": "d24cc82cf1bbd487",
        "hash_cont_tokens": "977312076fdfae5a"
      },
      "truncated": 0,
      "non_truncated": 151,
      "padded": 150,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_psychology|0": {
      "hashes": {
        "hash_examples": "edf05b5a00a1ffed",
        "hash_full_prompts": "edf05b5a00a1ffed",
        "hash_input_tokens": "5ffed76e4074f702",
        "hash_cont_tokens": "c5235b4fe61d0f28"
      },
      "truncated": 0,
      "non_truncated": 545,
      "padded": 544,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_statistics|0": {
      "hashes": {
        "hash_examples": "d05b84dce82cf271",
        "hash_full_prompts": "d05b84dce82cf271",
        "hash_input_tokens": "1f0d2eeb139759f8",
        "hash_cont_tokens": "8c2bb2584fe7fecc"
      },
      "truncated": 0,
      "non_truncated": 216,
      "padded": 216,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_us_history|0": {
      "hashes": {
        "hash_examples": "66f946395af34b57",
        "hash_full_prompts": "66f946395af34b57",
        "hash_input_tokens": "c2f776549c732a22",
        "hash_cont_tokens": "f698b43879323c5d"
      },
      "truncated": 0,
      "non_truncated": 204,
      "padded": 204,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:high_school_world_history|0": {
      "hashes": {
        "hash_examples": "6da47daf209b6906",
        "hash_full_prompts": "6da47daf209b6906",
        "hash_input_tokens": "0c2b862f1abfd8af",
        "hash_cont_tokens": "31d5e0bb671d4209"
      },
      "truncated": 0,
      "non_truncated": 237,
      "padded": 237,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:human_aging|0": {
      "hashes": {
        "hash_examples": "5102e080d6bbf2c9",
        "hash_full_prompts": "5102e080d6bbf2c9",
        "hash_input_tokens": "d31d33ab29046e4c",
        "hash_cont_tokens": "83163bb98610be8d"
      },
      "truncated": 0,
      "non_truncated": 223,
      "padded": 222,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:human_sexuality|0": {
      "hashes": {
        "hash_examples": "98e337d2ec74c071",
        "hash_full_prompts": "98e337d2ec74c071",
        "hash_input_tokens": "16d09dc9d70378ac",
        "hash_cont_tokens": "d3403eca0421789d"
      },
      "truncated": 0,
      "non_truncated": 131,
      "padded": 130,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:international_law|0": {
      "hashes": {
        "hash_examples": "024f4f79dea3148b",
        "hash_full_prompts": "024f4f79dea3148b",
        "hash_input_tokens": "3c355f7c2eae5725",
        "hash_cont_tokens": "de1ccf8a0329d3af"
      },
      "truncated": 0,
      "non_truncated": 121,
      "padded": 121,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:jurisprudence|0": {
      "hashes": {
        "hash_examples": "dbce560b991f24f7",
        "hash_full_prompts": "dbce560b991f24f7",
        "hash_input_tokens": "411ab00b7491671e",
        "hash_cont_tokens": "7c04a09184efb8bf"
      },
      "truncated": 0,
      "non_truncated": 108,
      "padded": 106,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:logical_fallacies|0": {
      "hashes": {
        "hash_examples": "ba2d54938233aa07",
        "hash_full_prompts": "ba2d54938233aa07",
        "hash_input_tokens": "92908848c9ae9afc",
        "hash_cont_tokens": "017b6606f06a3a01"
      },
      "truncated": 0,
      "non_truncated": 163,
      "padded": 163,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:machine_learning|0": {
      "hashes": {
        "hash_examples": "40908e2a26fb5c0e",
        "hash_full_prompts": "40908e2a26fb5c0e",
        "hash_input_tokens": "613485566d9f7824",
        "hash_cont_tokens": "d59db8f3737eda13"
      },
      "truncated": 0,
      "non_truncated": 112,
      "padded": 111,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:management|0": {
      "hashes": {
        "hash_examples": "a1f81faf23ea7a4a",
        "hash_full_prompts": "a1f81faf23ea7a4a",
        "hash_input_tokens": "c092d816489bf4c8",
        "hash_cont_tokens": "0b0bc4f1c10f0d81"
      },
      "truncated": 0,
      "non_truncated": 103,
      "padded": 103,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:marketing|0": {
      "hashes": {
        "hash_examples": "121766aea3a02ec6",
        "hash_full_prompts": "121766aea3a02ec6",
        "hash_input_tokens": "afb6b21b25e06f0b",
        "hash_cont_tokens": "18b24ca5cef62a52"
      },
      "truncated": 0,
      "non_truncated": 234,
      "padded": 233,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:medical_genetics|0": {
      "hashes": {
        "hash_examples": "a5234cbf1e185d9c",
        "hash_full_prompts": "a5234cbf1e185d9c",
        "hash_input_tokens": "dbc519104af029f8",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 99,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:miscellaneous|0": {
      "hashes": {
        "hash_examples": "0dca73ba594ef8e6",
        "hash_full_prompts": "0dca73ba594ef8e6",
        "hash_input_tokens": "f077d4ff48d78718",
        "hash_cont_tokens": "4d38366e1311a264"
      },
      "truncated": 0,
      "non_truncated": 783,
      "padded": 781,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:moral_disputes|0": {
      "hashes": {
        "hash_examples": "2f9d21d3c3d6dabf",
        "hash_full_prompts": "2f9d21d3c3d6dabf",
        "hash_input_tokens": "48993a9d94a951f0",
        "hash_cont_tokens": "1a63f0f09fa07f47"
      },
      "truncated": 0,
      "non_truncated": 346,
      "padded": 344,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:moral_scenarios|0": {
      "hashes": {
        "hash_examples": "288ae64806c743dd",
        "hash_full_prompts": "288ae64806c743dd",
        "hash_input_tokens": "241842a9f8d9fdf0",
        "hash_cont_tokens": "38d393ad6e062b21"
      },
      "truncated": 0,
      "non_truncated": 895,
      "padded": 895,
      "non_padded": 0,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:nutrition|0": {
      "hashes": {
        "hash_examples": "db24221d127f227e",
        "hash_full_prompts": "db24221d127f227e",
        "hash_input_tokens": "e2d75b0418e19421",
        "hash_cont_tokens": "7a717e1b47c5d3fe"
      },
      "truncated": 0,
      "non_truncated": 306,
      "padded": 304,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:philosophy|0": {
      "hashes": {
        "hash_examples": "48ce18251660ff1b",
        "hash_full_prompts": "48ce18251660ff1b",
        "hash_input_tokens": "7424bf5f75b878c0",
        "hash_cont_tokens": "ee7fd6161cce2730"
      },
      "truncated": 0,
      "non_truncated": 311,
      "padded": 309,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:prehistory|0": {
      "hashes": {
        "hash_examples": "4af763a8630b177c",
        "hash_full_prompts": "4af763a8630b177c",
        "hash_input_tokens": "c65abd1ab412a107",
        "hash_cont_tokens": "5252981022ca456b"
      },
      "truncated": 0,
      "non_truncated": 324,
      "padded": 320,
      "non_padded": 4,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:professional_accounting|0": {
      "hashes": {
        "hash_examples": "5868ab084283f40e",
        "hash_full_prompts": "5868ab084283f40e",
        "hash_input_tokens": "437dfcc99f252698",
        "hash_cont_tokens": "b1c8829b73f9b6b2"
      },
      "truncated": 0,
      "non_truncated": 282,
      "padded": 280,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:professional_law|0": {
      "hashes": {
        "hash_examples": "599dacf6a7b14f33",
        "hash_full_prompts": "599dacf6a7b14f33",
        "hash_input_tokens": "d39edd786f528d69",
        "hash_cont_tokens": "08346f2242422252"
      },
      "truncated": 0,
      "non_truncated": 1534,
      "padded": 1531,
      "non_padded": 3,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:professional_medicine|0": {
      "hashes": {
        "hash_examples": "06296b40c3b9cd52",
        "hash_full_prompts": "06296b40c3b9cd52",
        "hash_input_tokens": "13c41b66a253c51c",
        "hash_cont_tokens": "c414baf561994d05"
      },
      "truncated": 0,
      "non_truncated": 272,
      "padded": 271,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:professional_psychology|0": {
      "hashes": {
        "hash_examples": "e1e7c386f9af31f4",
        "hash_full_prompts": "e1e7c386f9af31f4",
        "hash_input_tokens": "192940c132ded0b6",
        "hash_cont_tokens": "7797eb4706643a31"
      },
      "truncated": 0,
      "non_truncated": 612,
      "padded": 606,
      "non_padded": 6,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:public_relations|0": {
      "hashes": {
        "hash_examples": "7279fdb9be580ec9",
        "hash_full_prompts": "7279fdb9be580ec9",
        "hash_input_tokens": "ea61d64705fb75cf",
        "hash_cont_tokens": "c6870e3b32fb97e1"
      },
      "truncated": 0,
      "non_truncated": 110,
      "padded": 109,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:security_studies|0": {
      "hashes": {
        "hash_examples": "d38efe48014b6b7a",
        "hash_full_prompts": "d38efe48014b6b7a",
        "hash_input_tokens": "291cbc623e8a0cbd",
        "hash_cont_tokens": "d14ae8a5cce9e838"
      },
      "truncated": 0,
      "non_truncated": 245,
      "padded": 244,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:sociology|0": {
      "hashes": {
        "hash_examples": "4fe67ce196e83f68",
        "hash_full_prompts": "4fe67ce196e83f68",
        "hash_input_tokens": "d752a220ca3c283c",
        "hash_cont_tokens": "a71e5c98fde23623"
      },
      "truncated": 0,
      "non_truncated": 201,
      "padded": 200,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:us_foreign_policy|0": {
      "hashes": {
        "hash_examples": "f93c7018528fa20a",
        "hash_full_prompts": "f93c7018528fa20a",
        "hash_input_tokens": "7fd8351b90b6ba9f",
        "hash_cont_tokens": "e474dfbc2deaf7d2"
      },
      "truncated": 0,
      "non_truncated": 100,
      "padded": 99,
      "non_padded": 1,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:virology|0": {
      "hashes": {
        "hash_examples": "7bc8324d3e7a3789",
        "hash_full_prompts": "7bc8324d3e7a3789",
        "hash_input_tokens": "1e2a3881014b6038",
        "hash_cont_tokens": "f7bdb3d8eee4c331"
      },
      "truncated": 0,
      "non_truncated": 166,
      "padded": 164,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    },
    "original|mmlu:world_religions|0": {
      "hashes": {
        "hash_examples": "8fedf589a9832190",
        "hash_full_prompts": "8fedf589a9832190",
        "hash_input_tokens": "9d1c672bdc3e89d4",
        "hash_cont_tokens": "27d253a22ac8c0f8"
      },
      "truncated": 0,
      "non_truncated": 171,
      "padded": 169,
      "non_padded": 2,
      "effective_few_shots": 0.0,
      "num_truncated_few_shots": 0
    }
  },
  "summary_general": {
    "hashes": {
      "hash_examples": "678bb6b5a21d9e9f",
      "hash_full_prompts": "678bb6b5a21d9e9f",
      "hash_input_tokens": "4c8a439edd65c9a3",
      "hash_cont_tokens": "d712b3adc3c81385"
    },
    "truncated": 0,
    "non_truncated": 14042,
    "padded": 13995,
    "non_padded": 47,
    "num_truncated_few_shots": 0
  }
}