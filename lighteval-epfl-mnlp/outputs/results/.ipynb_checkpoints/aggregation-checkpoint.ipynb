{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dee6987b-fc4a-4a1d-90b4-8a5ca518e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def process_json(file_path):\n",
    "    \"\"\"\n",
    "    Load a single JSON file, extract model_name and results,\n",
    "    and return a DataFrame with a MultiIndex (model_name, metric).\n",
    "    Also rename 'all' column conditionally.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    model_name = data[\"config_general\"][\"model_name\"]\n",
    "    results = data[\"results\"]\n",
    "\n",
    "    # Define the metric rows\n",
    "    metrics = [\"acc\", \"acc_stderr\", \"acc_norm\", \"acc_norm_stderr\"]\n",
    "\n",
    "    # Build a MultiIndex for the rows: (model_name, metric)\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [[model_name], metrics], names=[\"model_name\", \"metric\"]\n",
    "    )\n",
    "\n",
    "    # Prepare columns by stripping trailing '|<digits>' from each result key\n",
    "    cols = {}\n",
    "    for full_key, vals in results.items():\n",
    "        parts = full_key.split(\"|\")\n",
    "        # remove trailing numeric suffix\n",
    "        col = \"|\".join(parts[:-1]) if parts[-1].isdigit() else full_key\n",
    "        # Extract values in the same order as metrics\n",
    "        cols[col] = [vals.get(m) for m in metrics]\n",
    "\n",
    "    # Construct DataFrame\n",
    "    df = pd.DataFrame(cols, index=index)\n",
    "\n",
    "    # Rename 'all' column based on presence of community|mmlu:stem\n",
    "    if 'all' in df.columns:\n",
    "        if 'community|mmlu:stem' in df.columns:\n",
    "            df.rename(columns={'all': 'all_community'}, inplace=True)\n",
    "        else:\n",
    "            df.rename(columns={'all': 'all_lighteval'}, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de1b9864-48ff-4279-a3b9-0c920144d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = []\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith('.json'):\n",
    "            json_files.append(os.path.join(root, filename))\n",
    "\n",
    "# Process each JSON into a DataFrame\n",
    "dfs = []\n",
    "for jf in json_files:\n",
    "    try:\n",
    "        df = process_json(jf)\n",
    "        #print(df)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {jf}: {e}\")\n",
    "\n",
    "# Combine all DataFrames by stacking their rows (union on rows)\n",
    "# instead of axis=0 (stacking), do axis=1 (horizontal join)\n",
    "combined_df = pd.concat(dfs, axis=1, join='outer')\n",
    "combined_df = (\n",
    "    combined_df\n",
    "    .T\n",
    "    .groupby(level=0)    # group by the original column names (now the index)\n",
    "    .first()             # take the first non-null entry in each group\n",
    "    .T                   # transpose back\n",
    ")\n",
    "combined_df = combined_df.loc[:, ~combined_df.columns.str.startswith(\"all_\")]\n",
    "\n",
    "# write it out\n",
    "combined_df.to_csv(\"accuracy_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0068d28b-65e1-47ac-9b14-af04ddd13e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df\n",
    "\n",
    "# 1) drop all the “norm” rows by masking on the second level of the index:\n",
    "metric_level = df.index.get_level_values('metric')\n",
    "mask = ~metric_level.str.contains('norm')\n",
    "df2 = df[mask]\n",
    "\n",
    "# 2) unstack the metric level so acc & acc_stderr become sub-columns:\n",
    "df_un = df2.unstack(level='metric')\n",
    "# now df_un.columns is a MultiIndex of (dataset_name, metric_name)\n",
    "\n",
    "# 3) for each dataset, round and format “acc ± acc_stderr” into one string column:\n",
    "out = pd.DataFrame(index=df_un.index)\n",
    "for dataset in df_un.columns.levels[0]:\n",
    "    acc    = (df_un[(dataset, 'acc')]*100).round(2).map(\"{:.2f}\".format)\n",
    "    stderr = (df_un[(dataset, 'acc_stderr')]*100).round(2).map(\"{:.2f}\".format)\n",
    "    out[dataset] = acc + ' ± ' + stderr\n",
    "\n",
    "\n",
    "\n",
    "# 4) bring model_name back to a column if you like:\n",
    "out = out.reset_index()\n",
    "out.to_csv(\"pretty_accuracy_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2c)",
   "language": "python",
   "name": "mnlp_m2c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
