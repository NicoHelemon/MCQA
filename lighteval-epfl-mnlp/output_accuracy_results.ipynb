{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee6987b-fc4a-4a1d-90b4-8a5ca518e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def process_json(file_path):\n",
    "    \"\"\"\n",
    "    Load a single JSON file, extract model_name and results,\n",
    "    and return a DataFrame with a MultiIndex (model_name, metric).\n",
    "    Also rename 'all' column conditionally.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    #model_name = data[\"config_general\"][\"model_name\"]\n",
    "    path = Path(file_path)\n",
    "    model_name = '/'.join(path.parts[-3:-1])\n",
    "    if '.ipynb_checkpoints' in model_name:\n",
    "        return None\n",
    "    results = data[\"results\"]\n",
    "\n",
    "    # Define the metric rows\n",
    "    metrics = [\"acc\", \"acc_stderr\", \"acc_norm\", \"acc_norm_stderr\"]\n",
    "\n",
    "    # Build a MultiIndex for the rows: (model_name, metric)\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [[model_name], metrics], names=[\"model_name\", \"metric\"]\n",
    "    )\n",
    "\n",
    "    # Prepare columns by stripping trailing '|<digits>' from each result key\n",
    "    cols = {}\n",
    "    for full_key, vals in results.items():\n",
    "        parts = full_key.split(\"|\")\n",
    "        # remove trailing numeric suffix\n",
    "        col = \"|\".join(parts[:-1]) if parts[-1].isdigit() else full_key\n",
    "        # Extract values in the same order as metrics\n",
    "        cols[col] = [vals.get(m) for m in metrics]\n",
    "\n",
    "    # Construct DataFrame\n",
    "    df = pd.DataFrame(cols, index=index)\n",
    "\n",
    "    if \"original|mmlu:global_facts\" in df.columns:\n",
    "        # Drop every column that starts with \"original|mmlu:\"\n",
    "        cols_to_drop = [col for col in df.columns if col.startswith(\"original|mmlu:\")]\n",
    "        df.drop(columns=cols_to_drop, inplace=True)\n",
    "        # Keep \"all\" (if present) and rename it to \"original|mmlu\"\n",
    "        if \"all\" in df.columns:\n",
    "            df.rename(columns={\"all\": \"original|mmlu\"}, inplace=True)\n",
    "    else:\n",
    "        # If \"original|mmlu:global_facts\" is not present, drop \"all\" (if present)\n",
    "        if \"all\" in df.columns:\n",
    "            df.drop(columns=[\"all\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_mtime(path):\n",
    "    return os.path.getmtime(path)\n",
    "\n",
    "base_dir = 'outputs_mcqa/results'\n",
    "\n",
    "# 1. Collect and sort the JSON files by modification time (oldest to newest)\n",
    "json_files = []\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for filename in files:\n",
    "        if filename.lower().endswith('.json'):\n",
    "            full_path = os.path.join(root, filename)\n",
    "            json_files.append(full_path)\n",
    "# Sort so that newer files come last—they will override older ones in case of column name collisions\n",
    "json_files.sort(key=get_mtime)\n",
    "\n",
    "# 2. Process each JSON file into a DataFrame\n",
    "dfs = []\n",
    "for jf in json_files:\n",
    "    try:\n",
    "        df = process_json(jf)\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {jf}: {e}\")\n",
    "\n",
    "# 3. Horizontally concatenate all DataFrames (union on columns)\n",
    "combined_df = pd.concat(dfs, axis=1, join='outer')\n",
    "\n",
    "# 4. In case of duplicate columns, keep the *last* (newest) occurrence\n",
    "combined_df = (\n",
    "    combined_df\n",
    "    .T\n",
    "    .groupby(level=0)\n",
    "    .last()\n",
    "    .T\n",
    ")\n",
    "\n",
    "# 5. Define raw weights in a single dictionary and normalize over all tasks\n",
    "raw_weights = {\n",
    "    \"community|MNLP_M3_mcqa_dataset\": 0,\n",
    "    \"original|mmlu\": 0.0,\n",
    "    \"community|mmlu:stem\": 9,\n",
    "    \"community|mnlp_mcqa_evals\": 0,\n",
    "    \"community|mnlp_mcqa_evals_legacy\": 0,\n",
    "    \"helm|commonsenseqa\": 1,\n",
    "    \"helm|med_qa\": 2.5,\n",
    "    \"lighteval|agieval:aqua-rat\": 0.25,\n",
    "    \"lighteval|openbookqa\": 1,\n",
    "    \"lighteval|race:high\": 1,\n",
    "    \"lighteval|sciq\": 1,\n",
    "    \"original|arc:c:letters\": 1,\n",
    "}\n",
    "\n",
    "total_weight_raw = sum(raw_weights.values())\n",
    "\n",
    "d = {k: (v / total_weight_raw if total_weight_raw else 0) for k, v in raw_weights.items()}\n",
    "\n",
    "# Filter available columns and corresponding weights\n",
    "weight_cols = [col for col in d if col in combined_df.columns]\n",
    "weight_vals = [d[col] for col in weight_cols]\n",
    "\n",
    "# 6. Compute weighted mean using normalized weights\n",
    "total_weight = sum(weight_vals)\n",
    "combined_df[\"mean_weighted\"] = (\n",
    "    combined_df[weight_cols]\n",
    "    .multiply(weight_vals, axis=1)\n",
    "    .sum(axis=1)\n",
    "    / total_weight\n",
    ")\n",
    "\n",
    "# 7. Compute raw mean: use binary weights (1 if weight > 0, else 0)\n",
    "binary_weights = {col: 1 if d.get(col, 0) > 0 else 0 for col in d}\n",
    "bin_vals = [binary_weights[col] for col in weight_cols]\n",
    "norm = sum(bin_vals)\n",
    "combined_df[\"mean_raw\"] = (\n",
    "    combined_df[weight_cols]\n",
    "    .multiply(bin_vals, axis=1)\n",
    "    .sum(axis=1)\n",
    "    / norm\n",
    ")\n",
    "\n",
    "# 8. Reorder columns at the end\n",
    "desired_cols = [\n",
    "    \"mean_weighted\",\n",
    "    \"mean_raw\", \n",
    "    \"community|mmlu:stem\",\n",
    "    \"helm|commonsenseqa\",\n",
    "    \"helm|med_qa\",\n",
    "    \"lighteval|agieval:aqua-rat\",\n",
    "    \"lighteval|openbookqa\",\n",
    "    \"lighteval|race:high\",\n",
    "    \"lighteval|sciq\",\n",
    "    \"original|arc:c:letters\"\n",
    "    #\"community|MNLP_M3_mcqa_dataset\",\n",
    "    #\"original|mmlu\",\n",
    "    #\"community|mnlp_mcqa_evals\",\n",
    "    #\"community|mnlp_mcqa_evals_legacy\",\n",
    "]\n",
    "# Keep only columns present in the DataFrame, in the specified order\n",
    "ordered = [col for col in desired_cols if col in combined_df.columns]\n",
    "combined_df = combined_df[ordered]\n",
    "\n",
    "df = combined_df\n",
    "\n",
    "# 1) drop all the “norm” rows by masking on the second level of the index:\n",
    "metric_level = df.index.get_level_values('metric')\n",
    "mask = ~metric_level.str.contains('norm')\n",
    "df2 = df[mask]\n",
    "\n",
    "# 2) unstack the metric level so acc & acc_stderr become sub-columns:\n",
    "df_un = df2.unstack(level='metric')\n",
    "# now df_un.columns is a MultiIndex of (dataset_name, metric_name)\n",
    "\n",
    "# 3) for each dataset, round and format “acc ± acc_stderr” into one string column:\n",
    "out = pd.DataFrame(index=df_un.index)\n",
    "for dataset in df_un.columns.levels[0]:\n",
    "    acc    = (df_un[(dataset, 'acc')]*100).round(2).map(\"{:.2f}\".format)\n",
    "    #stderr = (df_un[(dataset, 'acc_stderr')]*100).round(2).map(\"{:.2f}\".format)\n",
    "    out[dataset] = acc #+ ' ± ' + stderr\n",
    "\n",
    "# Step 1: Extract the model_name level from the MultiIndex\n",
    "out = out.reset_index()  # This moves the index (model names) to a column named 'model_name'\n",
    "\n",
    "# Now we can safely modify the model_name column\n",
    "# Step 1: Truncate \"NicoHelemon/\" prefix\n",
    "out[\"model_name\"] = out[\"model_name\"].str.replace(r'^NicoHelemon/', '', regex=True)\n",
    "\n",
    "# Step 2: Apply rename_map\n",
    "rename_map = {\n",
    "    \"MNLP_M3_mcqa_model\": \"MNLP_M3_mcqa_model_cot00_e1\",\n",
    "    \"MNLP_M2_mcqa_model_cot00\": \"MNLP_M2_mcqa_model_cot00_e1\",\n",
    "    \"MNLP_M2_mcqa_model_cot10\": \"MNLP_M2_mcqa_model_cot10_e1\",\n",
    "}\n",
    "out[\"model_name\"] = out[\"model_name\"].replace(rename_map)\n",
    "\n",
    "# 4) bring model_name back to a column if you like:\n",
    "#out = out.reset_index()\n",
    "out.to_csv(\"accuracy_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mnlp_m2c)",
   "language": "python",
   "name": "mnlp_m2c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
